{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,Dense,Flatten,MaxPool2D\n",
    "from keras import regularizers\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop('label',axis=1)\n",
    "Y_train = train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       784\n",
       "unique        1\n",
       "top       False\n",
       "freq        784\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isnull().any().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       784\n",
       "unique        1\n",
       "top       False\n",
       "freq        784\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().any().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255.0\n",
    "test = test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values.reshape(-1,28,28,1)\n",
    "test = test.values.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = to_categorical(Y_train,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_cv, Y_train, Y_cv = train_test_split(X_train, Y_train, test_size = 0.2, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d813ae16a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = plt.imshow(X_train[0][:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hi\\AppData\\Local\\conda\\conda\\envs\\deep_learning\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1238: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\hi\\AppData\\Local\\conda\\conda\\envs\\deep_learning\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1255: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "### Model -> [[Conv->Relu(L2)]*2->MaxPool]*2->Flatten->Dense->L2->Output\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32,kernel_size=(5,5),strides=1,padding='Same',input_shape=[28,28,1],kernel_initializer='glorot_uniform', \n",
    "                 bias_initializer='zeros',activation='relu',kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Conv2D(filters=32,kernel_size=(5,5),strides=1,padding='Same',kernel_initializer='glorot_uniform',\n",
    "                 bias_initializer='zeros',activation='relu',kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=64,kernel_size=(5,5),strides=1,padding='Same',kernel_initializer='glorot_uniform', \n",
    "                 bias_initializer='zeros',activation='relu',kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Conv2D(filters=64,kernel_size=(5,5),strides=1,padding='Same',kernel_initializer='glorot_uniform',\n",
    "                 bias_initializer='zeros',activation='relu',kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256,activation='relu',kernel_initializer='glorot_uniform', bias_initializer='zeros', \n",
    "                kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hi\\AppData\\Local\\conda\\conda\\envs\\deep_learning\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1340: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc',patience=2,verbose=1, factor=0.5,min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(featurewise_center=False,\n",
    "                            samplewise_center=False,\n",
    "                            featurewise_std_normalization=False,\n",
    "                            samplewise_std_normalization=False,\n",
    "                            rotation_range=10,\n",
    "                            width_shift_range=0.1,\n",
    "                            height_shift_range=0.1,\n",
    "                            zoom_range=[0.9,1.1],\n",
    "                            horizontal_flip=False,\n",
    "                            vertical_flip=False)\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1050/1050 [==============================] - 564s 537ms/step - loss: 0.8024 - acc: 0.8897 - val_loss: 0.4062 - val_acc: 0.9618\n",
      "Epoch 2/10\n",
      "1050/1050 [==============================] - 561s 534ms/step - loss: 0.4525 - acc: 0.9407 - val_loss: 0.3237 - val_acc: 0.9742\n",
      "Epoch 3/10\n",
      "1050/1050 [==============================] - 550s 524ms/step - loss: 0.4067 - acc: 0.9463 - val_loss: 0.3164 - val_acc: 0.9705\n",
      "Epoch 4/10\n",
      "1050/1050 [==============================] - 563s 536ms/step - loss: 0.3762 - acc: 0.9500 - val_loss: 0.2960 - val_acc: 0.9736\n",
      "Epoch 5/10\n",
      "1049/1050 [============================>.] - ETA: 0s - loss: 0.3559 - acc: 0.9544\n",
      "Epoch 00005: reducing learning rate to 0.0005000000237487257.\n",
      "1050/1050 [==============================] - 581s 554ms/step - loss: 0.3559 - acc: 0.9544 - val_loss: 0.2827 - val_acc: 0.9723\n",
      "Epoch 6/10\n",
      "1050/1050 [==============================] - 571s 543ms/step - loss: 0.2943 - acc: 0.9624 - val_loss: 0.2447 - val_acc: 0.9732\n",
      "Epoch 7/10\n",
      "1049/1050 [============================>.] - ETA: 0s - loss: 0.2806 - acc: 0.9626\n",
      "Epoch 00007: reducing learning rate to 0.0002500000118743628.\n",
      "1050/1050 [==============================] - 564s 537ms/step - loss: 0.2805 - acc: 0.9627 - val_loss: 0.2439 - val_acc: 0.9724\n",
      "Epoch 8/10\n",
      "1050/1050 [==============================] - 586s 558ms/step - loss: 0.2461 - acc: 0.9712 - val_loss: 0.2023 - val_acc: 0.9807\n",
      "Epoch 9/10\n",
      "1050/1050 [==============================] - 551s 524ms/step - loss: 0.2418 - acc: 0.9697 - val_loss: 0.1976 - val_acc: 0.9813\n",
      "Epoch 10/10\n",
      "1050/1050 [==============================] - 551s 524ms/step - loss: 0.2383 - acc: 0.9695 - val_loss: 0.1940 - val_acc: 0.9839\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d8149e8b00>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(datagen.flow(X_train,Y_train,batch_size=batch_size),epochs=epochs,steps_per_epoch=(X_train.shape[0]/batch_size),\n",
    "                   validation_data=(X_cv,Y_cv),callbacks=[learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[811,   0,   0,   0,   0,   0,   2,   0,   1,   2],\n",
       "       [  0, 902,   4,   0,   0,   0,   1,   2,   0,   0],\n",
       "       [  1,   3, 835,   1,   0,   0,   0,   3,   2,   1],\n",
       "       [  0,   0,   3, 913,   0,   5,   0,   6,   6,   4],\n",
       "       [  0,   1,   0,   0, 824,   0,   3,   2,   0,   9],\n",
       "       [  1,   0,   0,   3,   0, 688,   5,   0,   2,   3],\n",
       "       [  2,   0,   0,   0,   6,   0, 776,   0,   1,   0],\n",
       "       [  0,   0,   5,   0,   0,   0,   0, 884,   1,   3],\n",
       "       [  0,   3,   5,   0,   2,   1,   4,   2, 815,   3],\n",
       "       [  0,   2,   1,   2,   3,   2,   0,   9,   2, 817]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = model.predict(X_cv)\n",
    "Y_pred_digit = np.argmax(Y_pred,axis=1)\n",
    "Y_true = np.argmax(Y_cv,axis=1)\n",
    "confusion_matrix(Y_true,Y_pred_digit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(test)\n",
    "results = np.argmax(results,axis = 1)\n",
    "results = pd.Series(results,name=\"Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n",
    "submission.to_csv(\"digit_recognizer_data_augmentation.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
